# Sign-Language-Recognition
Sign Language Recognition focuses on developing software or hardware solutions that can recognize and interpret sign language gestures and movements made by individuals with hearing or speech impairments. Sign language is a visual language that uses a combination of hand gestures, facial expressions, and body language to convey information and meaning. It is used by millions of people worldwide as their primary means of communication. However, for those who do not understand sign language, communication with individuals who use it can be challenging.
The goal of sign language recognition is to bridge this communication gap by developing technology that can accurately interpret sign language gestures and translate them into spoken or written language. This can help individuals who use sign language to communicate more effectively with those who do not.
There are several approaches to sign language recognition, including computer vision and machine learning techniques. These methods involve training models to recognize and interpret different sign language gestures and movements based on visual data. With the help of these techniques, it is possible to create systems that can recognize a wide range of sign language gestures and translate them into spoken or written language in real-time.

Objectives of the project

• To recognize hand gestures which include 26 English alphabets (A-Z) and 10 digits (0-9) using Convolutional Neural Network.

• To convert sign language into words by an algorithm or a model.

• To show on optical viewfinder of camera module what a particular position of hand means with respect to sign language.

The data set made by us:

Data Collection: https://drive.google.com/drive/folders/1yehHJ2qjmHmDiuX3lPvHwWF0CwY9HHSa?usp=sharing

Pre Processed Data : https://drive.google.com/drive/folders/12kb1chVIild_K9tpWDHw1KBkMFMvrP97?usp=sharing
